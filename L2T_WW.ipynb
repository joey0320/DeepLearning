{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgN0Z2A_Dwg-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2a9fd7cc-e427-4344-d9fc-b3b770f960bd"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as tfs\n",
        "import torchvision.models as models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import trange\n",
        "import torch.nn.init as init\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = 'cuda'\n",
        "else:\n",
        "  device='cpu'\n",
        "print(device)\n",
        "\n",
        "batch_size = 32\n",
        "lr = 1e-3\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9Nhlgt4McSA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Conv2d_(input_channels, output_channels, kernel_size_=3, padding_=1):\n",
        "  return nn.Conv2d(input_channels, output_channels, kernel_size=kernel_size_, padding=padding_)\n",
        "\n",
        "class VGG16(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(VGG16, self).__init__()\n",
        "    self.cnn1 = Conv2d_(3, 64)\n",
        "    self.cnn2 = Conv2d_(64, 128)\n",
        "    self.cnn3 = Conv2d_(128, 256)\n",
        "    self.cnn4 = Conv2d_(256, 256)\n",
        "    self.cnn5 = Conv2d_(256, 512)\n",
        "    self.cnn6 = Conv2d_(512, 512)\n",
        "    self.cnn7 = Conv2d_(512, 512)\n",
        "    self.cnn8 = Conv2d_(512, 512)\n",
        "    self.fcc = nn.Linear(512, 10)\n",
        "  \n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = F.max_pool2d(F.relu(self.cnn1(x)), (2, 2))\n",
        "    x = F.max_pool2d(F.relu(self.cnn2(x)), (2, 2))\n",
        "    x = F.max_pool2d(F.relu(self.cnn4(F.relu(self.cnn3(x)))), (2, 2))\n",
        "    x = F.max_pool2d(F.relu(self.cnn6(F.relu(self.cnn5(x)))), (2, 2))\n",
        "    x = F.max_pool2d(F.relu(self.cnn8(F.relu(self.cnn7(x)))), (2, 2))\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.fcc(x)\n",
        "    return x\n",
        "  \n",
        "  def forward_features(self, x):\n",
        "    f1 = F.max_pool2d(F.relu(self.cnn1(x)), (2, 2))\n",
        "    f2 = F.max_pool2d(F.relu(self.cnn2(f1)), (2, 2))\n",
        "    f3 = F.max_pool2d(F.relu(self.cnn4(F.relu(self.cnn3(f2)))), (2, 2))\n",
        "    f4 = F.max_pool2d(F.relu(self.cnn6(F.relu(self.cnn5(f3)))), (2, 2))\n",
        "    f5 = F.max_pool2d(F.relu(self.cnn8(F.relu(self.cnn7(f4)))), (2, 2))\n",
        "    feature = f5.view(f5.size(0), -1)\n",
        "    x = self.fcc(feature)\n",
        "    return x, [f1, f2, f3, f4, f5]\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aR-ajY5T6TW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def _weights_init(m):\n",
        "  classname = m.__class__.__name__\n",
        "  #print(classname)\n",
        "  if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
        "    init.kaiming_normal_(m.weight)\n",
        "\n",
        "class LambdaLayer(nn.Module):\n",
        "  def __init__(self, lambd):\n",
        "    super(LambdaLayer, self).__init__()\n",
        "    self.lambd = lambd\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.lambd(x)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "  expansion = 1\n",
        "\n",
        "  def __init__(self, in_planes, planes, stride=1, option='A'):\n",
        "    super(BasicBlock, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(planes)\n",
        "    self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "    self.shortcut = nn.Sequential()\n",
        "    if stride != 1 or in_planes != planes:\n",
        "      if option == 'A':\n",
        "        \"\"\"\n",
        "        For CIFAR10 ResNet paper uses option A.\n",
        "        \"\"\"\n",
        "        self.shortcut = LambdaLayer(lambda x:\n",
        "        F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n",
        "      elif option == 'B':\n",
        "        self.shortcut = nn.Sequential(\n",
        "                        nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
        "                        nn.BatchNorm2d(self.expansion * planes) )\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = F.relu(self.bn1(self.conv1(x)))\n",
        "    out = self.bn2(self.conv2(out))\n",
        "    out += self.shortcut(x)\n",
        "    out = F.relu(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "  def __init__(self, block, num_blocks, num_classes=10):\n",
        "    super(ResNet, self).__init__()\n",
        "    self.in_planes = 16\n",
        "\n",
        "    self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(16)\n",
        "    self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
        "    self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
        "    self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
        "    self.linear = nn.Linear(64, num_classes)\n",
        "\n",
        "    self.apply(_weights_init)\n",
        "\n",
        "  def _make_layer(self, block, planes, num_blocks, stride):\n",
        "    strides = [stride] + [1]*(num_blocks-1)\n",
        "    layers = []\n",
        "    for stride in strides:\n",
        "      layers.append(block(self.in_planes, planes, stride))\n",
        "      self.in_planes = planes * block.expansion\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = F.relu(self.bn1(self.conv1(x)))\n",
        "    out = self.layer1(out)\n",
        "    out = self.layer2(out)\n",
        "    out = self.layer3(out)\n",
        "    out = F.avg_pool2d(out, out.size()[3])\n",
        "    out = out.view(out.size(0), -1)\n",
        "    out = self.linear(out)\n",
        "    return out\n",
        "\n",
        "  def forward_features(self, x):\n",
        "    x = F.relu(self.bn1(self.conv1(x)))\n",
        "    f1 = self.layer1(x)\n",
        "    f2 = self.layer2(f1)\n",
        "    f3 = self.layer3(f2)\n",
        "    out = F.avg_pool2d(f3, f3.size()[3])\n",
        "    out = out.view(out.size(0), -1)\n",
        "    out = self.linear(out)\n",
        "    return out, [f1, f2, f3]\n",
        "\n",
        "def ResNet32():\n",
        "    return ResNet(BasicBlock, [5, 5, 5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvz0N-cBXJXz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sourceNet = ResNet32()\n",
        "targetNet = VGG16()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyHLG30WYSXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getloss(net, x, y, loss_fn):\n",
        "  y_ = net(x)\n",
        "  loss = loss_fn(y_, y)\n",
        "  return loss\n",
        "\n",
        "def backprop(loss, optimizer):\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "def trainsource(sourcenet, trainloader, valloader, epochs, lr, device):\n",
        "  sourceNet.to(device)\n",
        "  optimizer = optim.Adam(sourcenet.parameters(), lr=lr)\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "  min_val_loss = 1e9\n",
        "\n",
        "  for epoch in trange(epochs):\n",
        "    losses = []\n",
        "    for step, data in enumerate(trainloader):\n",
        "      x, y = data\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "      \n",
        "      y_ = sourcenet(x)\n",
        "      loss = loss_fn(y_, y)\n",
        "      backprop(loss, optimizer)\n",
        "      losses.append(loss.item())\n",
        "    avg_train_loss = sum(losses) / len(losses)\n",
        "    losses = []\n",
        "\n",
        "    for step, data in enumerate(valloader):\n",
        "      x, y = data\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "      loss = getloss(sourcenet, x, y, loss_fn)\n",
        "      losses.append(loss.item())\n",
        "    avg_val_loss = sum(losses) / len(losses)\n",
        "    \n",
        "    print(f'epoch {epoch} finished ===========> train loss : {avg_train_loss},    val loss : {avg_val_loss}')\n",
        "    if min_val_loss >= avg_val_loss:\n",
        "      print(f\"valid loss decreased from {min_val_loss} to {avg_val_loss}\")\n",
        "      min_val_loss = avg_val_loss\n",
        "      torch.save(sourcenet.state_dict(), f'sourcenet{epoch}.pt')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7CoI6z1hHkh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FeatureWeight(nn.Module):\n",
        "  #returns weights btw features : lambda(m, n)\n",
        "\n",
        "  def __init__(self, source_feature_volume):\n",
        "    super(FeatureWeight, self).__init__()\n",
        "    self.fcc = nn.Linear(source_feature_volume, 1)\n",
        "  \n",
        "  def forward(self, source_feature):\n",
        "    source_feature = source_feature.view(source_feature.size(0), -1)\n",
        "    lambda_weight = F.relu6(self.fcc(source_feature))\n",
        "    return lambda_weight\n",
        "\n",
        "class ChannelWeight(nn.Module):\n",
        "  #returns weights btw channels : w(m, n)\n",
        "\n",
        "  def __init__(self, source_feature_WH):\n",
        "    super(ChannelWeight, self).__init__()\n",
        "    self.fcc = nn.Linear(source_feature_WH, 1)\n",
        "\n",
        "  def forward(self, source_feature):\n",
        "    batch_num, channel_num, W, H = source_feature.shape\n",
        "    source_feature = source_feature.view(batch_num * channel_num, -1)\n",
        "    output = self.fcc(source_feature)\n",
        "    output = F.softmax(output.view(batch_num, -1), dim=1)\n",
        "    return output\n",
        "\n",
        "class Rnet(nn.Module):\n",
        "  #point convolution net\n",
        "\n",
        "  def __init__(self, target_channels, source_channels):\n",
        "    super(Rnet, self).__init__()\n",
        "    self.cnn = nn.Conv2d(target_channels, source_channels, kernel_size=1)\n",
        "  \n",
        "  def forward(self, target_features):\n",
        "    output = self.cnn(target_features)\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fagX7jr8rRkR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# source from\n",
        "# https://github.com/alinlab/L2T-ww/blob/master/train_l2t_ww.py\n",
        "\n",
        "def weight_feature_matching(S, rT):\n",
        "  wS = S.size(3)\n",
        "  wT = rT.size(3)\n",
        "\n",
        "  if wS==wT:\n",
        "    delta = S - rT\n",
        "  else:\n",
        "    delta = F.interpolate(S, scale_factor=wT/wS, mode='bilinear') - rT\n",
        "  \n",
        "  loss = delta.pow(2).mean(3).mean(2)\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4SX-yPWwUgx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "4ef20f87-dac9-4f04-f99d-fd8f1ef38de8"
      },
      "source": [
        "dumy = torch.zeros((32, 3, 32, 32))\n",
        "outputS, sFeatures = sourceNet.forward_features(dumy)\n",
        "outputT, tFeatures = targetNet.forward_features(dumy)\n",
        "print('source features')\n",
        "for sf in sFeatures:\n",
        "  print(sf.shape)\n",
        "\n",
        "print('target features')\n",
        "for tf in tFeatures:\n",
        "  print(tf.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "source features\n",
            "torch.Size([32, 16, 32, 32])\n",
            "torch.Size([32, 32, 16, 16])\n",
            "torch.Size([32, 64, 8, 8])\n",
            "target features\n",
            "torch.Size([32, 64, 16, 16])\n",
            "torch.Size([32, 128, 8, 8])\n",
            "torch.Size([32, 256, 4, 4])\n",
            "torch.Size([32, 512, 2, 2])\n",
            "torch.Size([32, 512, 1, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99jq2HAnwwpl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sSize = [(16, 32, 32), (32, 16, 16), (64, 8, 8)]\n",
        "tSize = [(64, 16, 16), (128, 8, 8), (256, 4, 4), (512, 2, 2), (512, 1, 1)]\n",
        "\n",
        "def init_metanet(sSize, tSize):\n",
        "  metaNet = []\n",
        "  for sidx in range(len(sSize)):\n",
        "    tlist = []\n",
        "    for tidx in range(len(tSize)):\n",
        "      sC, sW, sH = sSize[sidx]\n",
        "      tC, tW, tH = tSize[tidx]\n",
        "\n",
        "      fNet = FeatureWeight(sC * sW * sH)\n",
        "      cNet = ChannelWeight(sW * sH)\n",
        "      rNet = Rnet(tC, sC)\n",
        "      tlist.append((fNet, cNet, rNet))\n",
        "    metaNet.append(tlist)\n",
        "  \n",
        "  return metaNet\n",
        "\n",
        "metaNet = init_metanet(sSize, tSize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OG5rhP8x0Dkk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Loss_wfm(tNet, sNet, metaNet, x, y):\n",
        "  yt, tFeatures = tNet.forward_features(x)\n",
        "  ys, sFeatures = sNet.forward_features(x)\n",
        "\n",
        "  loss = 0\n",
        "  for sidx in range(len(sFeatures)):\n",
        "    for tidx in range(len(tFeatures)):\n",
        "      fNet, cNet, rNet = metaNet[sidx][tidx]\n",
        "      tfeature = tFeatures[tidx]\n",
        "      sfeature = sFeatures[sidx]\n",
        "\n",
        "      loss_cij = weight_feature_matching(sfeature, rNet(tfeature))\n",
        "      w_cmn = cNet(sfeature)\n",
        "      loss_wfm_mn = torch.sum(w_cmn * loss_cij, dim=1)\n",
        "\n",
        "      lambda_mn = fNet(sfeature)\n",
        "      loss += torch.sum(lambda_mn * loss_wfm_mn)\n",
        "  return loss\n",
        "\n",
        "def Loss_ori(tNet, x, y):\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "  y_ = tNet(x)\n",
        "  loss = loss_fn(y_, y)\n",
        "  return loss\n",
        "\n",
        "def Loss_tot(tNet, sNet, metaNet, beta, x, y):\n",
        "  return Loss_ori(tNet, x, y) + beta * Loss_wfm(tNet, sNet, metaNet, x, y) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jURunj_v3VOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def backprop_retain(loss, optimizer):\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward(retain_graph=True)\n",
        "  optimizer.step()\n",
        "\n",
        "def backprop_meta(loss, meta_optimizer, slen, tlen):\n",
        "  for sidx in range(slen):\n",
        "    for tidx in range(tlen):\n",
        "      foptim, coptim, roptim = meta_optimizer[sidx][tidx]\n",
        "      backprop_retain(loss.clone(), foptim)\n",
        "      backprop_retain(loss.clone(), coptim)\n",
        "      backprop_retain(loss.clone(), roptim)\n",
        "\n",
        "def metaNet_init_optim(metaNet, lr, device):\n",
        "  mOptim = []\n",
        "  for sidx in range(len(metaNet)):\n",
        "    fcrOptim = []\n",
        "    for tidx in range(len(metaNet[sidx])):\n",
        "      fNet, cNet, rNet = metaNet[sidx][tidx]\n",
        "      fNet.to(device)\n",
        "      cNet.to(device)\n",
        "      rNet.to(device)\n",
        "\n",
        "      foptim = optim.Adam(fNet.parameters(), lr=lr)\n",
        "      coptim = optim.Adam(cNet.parameters(), lr=lr)\n",
        "      roptim = optim.Adam(rNet.parameters(), lr=lr)\n",
        "      fcrOptim.append((foptim, coptim, roptim))\n",
        "\n",
        "    mOptim.append(fcrOptim)\n",
        "  return mOptim\n",
        "\n",
        "def metaNet_prepare_train(metaNet):\n",
        "  for sidx in range(len(metaNet)):\n",
        "    for tidx in range(len(metaNet[sidx])):\n",
        "      fNet, cNet, rNet = metaNet[sidx][tidx]\n",
        "      fNet.train()\n",
        "      cNet.train()\n",
        "      rNet.train()\n",
        "\n",
        "def metaNet_prepare_test(metaNet):\n",
        "  for sidx in range(len(metaNet)):\n",
        "    for tidx in range(len(metaNet[sidx])):\n",
        "      fNet, cNet, rNet = metaNet[sidx][tidx]\n",
        "      fNet.eval()\n",
        "      cNet.eval()\n",
        "      rNet.eval()\n",
        "\n",
        "def TrainWWT(tNet, sNet, metaNet, trainloader, valloader, epochs, lr, T, beta, device):\n",
        "  tNet.to(device)\n",
        "  sNet.to(device)\n",
        "  tOptim = optim.Adam(tNet.parameters(), lr=lr)\n",
        "  mOptim = metaNet_init_optim(metaNet, lr, device)\n",
        "\n",
        "  for epoch in trange(epochs):\n",
        "    tot_losses = []\n",
        "    ori_losses = []\n",
        "    wfm_losses = []\n",
        "\n",
        "    sNet.eval()\n",
        "    tNet.train()\n",
        "    metaNet_prepare_train(metaNet)\n",
        "\n",
        "    for step, data in enumerate(trainloader):\n",
        "      x, y = data\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "\n",
        "      tot_loss = Loss_tot(tNet, sNet, metaNet, beta, x, y)\n",
        "      backprop(tot_loss, tOptim)\n",
        "      tot_losses.append(tot_loss.item())\n",
        "\n",
        "      for t in range(T):\n",
        "        wfm_loss = Loss_wfm(tNet, sNet, metaNet, x, y)\n",
        "        backprop(wfm_loss, tOptim)\n",
        "        wfm_losses.append(wfm_loss.item())\n",
        "      \n",
        "      ori_loss = Loss_ori(tNet, x, y)\n",
        "      backprop(ori_loss, tOptim)\n",
        "      \n",
        "      ori_loss = Loss_ori(tNet, x, y)\n",
        "      backprop_meta(ori_loss, mOptim, len(metaNet), len(metaNet[0]))\n",
        "      ori_losses.append(ori_loss.item())\n",
        "    \n",
        "    avg_tot_loss = sum(tot_losses) / len(tot_losses)\n",
        "    avg_ori_loss = sum(ori_losses) / len(ori_losses)\n",
        "    avg_wfm_loss = sum(wfm_losses) / len(wfm_losses)\n",
        "    print(f'epoch : {epoch}  train step =======>  avg_tot_loss : {avg_tot_loss}   avg_ori_loss : {avg_ori_loss},  avg_wfm_loss : {avg_wfm_loss}')\n",
        "\n",
        "    metaNet_prepare_test(metaNet)\n",
        "    sNet.eval()\n",
        "    tNet.eval()\n",
        "\n",
        "    tot_losses = []\n",
        "    ori_losses = []\n",
        "    wfm_losses = []\n",
        "    for step, data in enumerate(valloader):\n",
        "      x, y = data\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "\n",
        "      tot_loss = loss_tot(tNet, sNet, metaNet, beta, x, y)\n",
        "      wfm_loss = loss_wfm(tNet, sNet, metaNet, x, y)\n",
        "      ori_loss = loss_ori(tNet, x, y)\n",
        "      tot_losses.append(tot_loss.item())\n",
        "      wfm_losses.append(wfm_loss.item())\n",
        "      ori_losses.append(ori_loss.item())\n",
        "\n",
        "    avg_tot_loss = sum(tot_losses) / len(tot_losses)\n",
        "    avg_ori_loss = sum(ori_losses) / len(ori_losses)\n",
        "    avg_wfm_loss = sum(wfm_losses) / len(wfm_losses)\n",
        "    print(f'epoch : {epoch}  valid step =======>  avg_tot_loss : {avg_tot_loss}   avg_ori_loss : {avg_ori_loss},  avg_wfm_loss : {avg_wfm_loss}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXEH3fU8PtWI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load data and train source net....\n",
        "#don't have access to tiny imagenet... I'm sorry\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rylt4u758cW0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "outputId": "04b9ae43-413d-4242-d1af-1b237054826f"
      },
      "source": [
        "transform = tfs.Compose([tfs.ToTensor(), tfs.Normalize(0.5, 0.5)])\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "valset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
        "valloader = DataLoader(valset, batch_size=32, shuffle=True)\n",
        "\n",
        "TrainWWT(targetNet, sourceNet, metaNet, trainloader, valloader, 2, 1e-3, 2, 1e-7, device)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-9cdf0664b1ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mvalloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mTrainWWT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargetNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msourceNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetaNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-04df74d1c909>\u001b[0m in \u001b[0;36mTrainWWT\u001b[0;34m(tNet, sNet, metaNet, trainloader, valloader, epochs, lr, T, beta, device)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mwfm_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoss_wfm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetaNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mbackprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwfm_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtOptim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mwfm_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwfm_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-41daee1c4823>\u001b[0m in \u001b[0;36mLoss_wfm\u001b[0;34m(tNet, sNet, metaNet, x, y)\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0msfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msFeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msidx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m       \u001b[0mloss_cij\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight_feature_matching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m       \u001b[0mw_cmn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0mloss_wfm_mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_cmn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mloss_cij\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-d7b5decba891>\u001b[0m in \u001b[0;36mweight_feature_matching\u001b[0;34m(S, rT)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mS\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwT\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mwS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bilinear'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36minterpolate\u001b[0;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor)\u001b[0m\n\u001b[1;32m   2975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2976\u001b[0m     \u001b[0mscale_factor_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2977\u001b[0;31m     \u001b[0mscale_factor_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale_factor_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2978\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mscale_factor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrecompute_scale_factor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2979\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU1P6jbKASmC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}