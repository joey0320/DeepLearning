{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Supervised Constr.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPEzHELE_mQG",
        "colab_type": "text"
      },
      "source": [
        "Supervised Contrastive Loss\n",
        "  - use colab\n",
        "  - use cifar-10(a reduced version of the paper)\n",
        "  - closer to a tutorial\n",
        "\n",
        "Instructions\n",
        "  - make a directory(folder) in google drive named state_dict\n",
        "    - you can use different paths by changing the code\n",
        "    \n",
        "  \n",
        "\n",
        "Feel free to use!!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgKcYkZQqxLI",
        "colab_type": "code",
        "outputId": "763b5036-5bab-4676-df99-ad7243f97435",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQZIcO-DkuHy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms as tfs\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm\n",
        "from tqdm import trange"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-LFIYtImjdl",
        "colab_type": "code",
        "outputId": "73ee7a07-6daa-45c3-c906-c9c890ea7484",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "config = {'batch_size':128, \n",
        "          'lr_embed':1e-3,\n",
        "          'lr_proj':1e-4,\n",
        "          'epochs_embed':700,\n",
        "          'epochs_proj':10,\n",
        "          'T':0.1, \n",
        "          'mean':0.5, \n",
        "          'std':0.5, \n",
        "          'dataset':'CIFAR-10'}\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device='cuda'\n",
        "else:\n",
        "  device='cpu'\n",
        "print(device)\n",
        "\n",
        "\n",
        "if config['dataset'] == 'CIFAR-10':\n",
        "  output_size = 10\n",
        "elif config['dataset'] == 'CIFAR-100':\n",
        "  output_size=100\n",
        "else:\n",
        "  raise NameError('wrong dataset name : dataset name should be CIFAR-10 or CIFAR-100')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubtTZdTcnCPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Aug2:\n",
        "  def __init__(self, tfs):\n",
        "    self._tfs = tfs\n",
        "  \n",
        "  def __call__(self, x):\n",
        "    return [self._tfs(x), self._tfs(x)]\n",
        "\n",
        "#generate a pair of augmented data\n",
        "def AugmentDataset(dataset='CIFAR-10', split='train', download=True, size=32, mean=0.5, std=0.5):\n",
        "  _transforms = tfs.Compose([tfs.RandomResizedCrop(size, scale=(0.75, 1.25)),\n",
        "                             tfs.RandomGrayscale(0.2),\n",
        "                             tfs.RandomHorizontalFlip(0.3),\n",
        "                             tfs.ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.2), saturation=(0.8, 1.2)),\n",
        "                             tfs.RandomAffine(degrees=(-10, 10), translate=(0.01, 0.05), scale=(0.9, 1.1), shear=(0, 5), fillcolor=0),\n",
        "                             tfs.ToTensor(),\n",
        "                             tfs.Normalize(mean=(mean,), std=(std,))])\n",
        "\n",
        "  if split=='train':\n",
        "   train=True\n",
        "  elif split=='val' or split=='test':\n",
        "   train=False\n",
        "  else:\n",
        "    raise NameError('split should be train, test, or val')\n",
        "\n",
        "  if dataset=='CIFAR-10':\n",
        "    _data = torchvision.datasets.CIFAR10(root='./data', \n",
        "                                         train=train, \n",
        "                                         transform=Aug2(_transforms), \n",
        "                                         download=download)\n",
        "  elif dataset=='CIFAR-100':\n",
        "    _data = torchvision.datasets.CIFAR100(root='./data', \n",
        "                                          train=train, \n",
        "                                          transform=Aug2(_transforms), \n",
        "                                          download=download)\n",
        "\n",
        "  print(len(_data))\n",
        "  return _data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TwW7k99t4IW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = AugmentDataset(dataset=config['dataset'], split='train', download=True, size=32, mean=config['mean'], std=config['std'])\n",
        "val_dataset = AugmentDataset(dataset=config['dataset'], split='val', download=True, size=32, mean=config['mean'], std=config['std'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uP33WCgjuOUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#train, validation data loader\n",
        "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, drop_last=False)\n",
        "val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=True, drop_last=False)\n",
        "\n",
        "def imshow(x):\n",
        "  x = x.numpy()\n",
        "  x = x * config['std'] + config['mean']\n",
        "  x = np.transpose(x, [1, 2, 0])\n",
        "  plt.imshow(x)\n",
        "  plt.show()\n",
        "\n",
        "#we should check data the data is loader properly\n",
        "def checkdata(dataloader):\n",
        "  for step, data in enumerate(dataloader):\n",
        "    x, y = data\n",
        "    print(x[0].shape)\n",
        "    print(x[1].shape)\n",
        "    print(y.shape)\n",
        "\n",
        "    imshow(x[0][0])\n",
        "    imshow(x[1][0])\n",
        "    print(y[0])\n",
        "    break\n",
        "checkdata(train_loader)\n",
        "checkdata(val_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLm-rx0qv6WN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#in the paper it uses Resnet 50\n",
        "\n",
        "#but here I will use a custum net \n",
        "#for the sake of simplicity & a limited computational resources\n",
        "def conv3(input_channels, output_channels):\n",
        "  return nn.Conv2d(input_channels, output_channels, kernel_size=3, padding=1)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "\n",
        "  def __init__(self, output_channels):\n",
        "    super(Encoder, self).__init__()\n",
        "    \n",
        "    self.cnn1 = conv3(3, 8)\n",
        "    self.cnn2 = conv3(8, 12)\n",
        "    self.cnn3 = conv3(12, 16)\n",
        "    self.cnn4 = conv3(16, 20)\n",
        "    self.cnn5 = conv3(20, output_channels)\n",
        "  \n",
        "  def forward(self, x1, x2):\n",
        "    return self._forward_single(x1), self._forward_single(x2)\n",
        "\n",
        "\n",
        "  def _forward_single(self, x):\n",
        "    x = F.max_pool2d(F.relu(self.cnn1(x)), (2, 2))\n",
        "    x = F.max_pool2d(F.relu(self.cnn2(x)), (2, 2))\n",
        "    x = F.max_pool2d(F.relu(self.cnn3(x)), (2, 2))\n",
        "    x = F.max_pool2d(F.relu(self.cnn4(x)), (2, 2))\n",
        "    x = F.max_pool2d(F.relu(self.cnn5(x)), (2, 2))\n",
        "    x = F.normalize(x, p=2, dim=1)\n",
        "    return x\n",
        "\n",
        "\n",
        "class Projection(nn.Module):\n",
        "\n",
        "  def __init__(self, input_size, output_size, type_='perceptron'):\n",
        "    super(Projection, self).__init__()\n",
        "\n",
        "    if type_=='perceptron':\n",
        "      self._layers = nn.Sequential(\n",
        "          nn.Linear(input_size, input_size),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(input_size, output_size)\n",
        "      )\n",
        "    elif type_=='linear':\n",
        "      self._layers = nn.Linear(input_size, output_size)\n",
        "    else:\n",
        "      raise NameError('type_ should be a string type of perceptron or linear')\n",
        "\n",
        "  def forward(self, x1, x2):\n",
        "    return torch.cat([self._forward_single(x1), self._forward_single(x2)], dim=0)\n",
        "\n",
        "\n",
        "  def _forward_single(self, x):\n",
        "    return F.normalize(self._layers(x), p=2, dim=1)\n",
        "\n",
        "class SupConNet(nn.Module):\n",
        "\n",
        "  def __init__(self, enet, pnet):\n",
        "    super(SupConNet, self).__init__()\n",
        "    self._enet = enet\n",
        "    self._pnet = pnet\n",
        "\n",
        "  def forward(self, x1, x2):\n",
        "    r1, r2 = self._enet(x1, x2)\n",
        "    r1, r2 = r1.view(r1.size(0), -1), r2.view(r2.size(0), -1)\n",
        "    z = self._pnet(r1, r2)\n",
        "    return z\n",
        "\n",
        "  #when training the embedding, we need to apply gradiennts to \n",
        "  #both the embedding layer, and the perceptron layer\n",
        "  def train_embedding(self):\n",
        "    self._enet.train()\n",
        "    self._pnet.train()\n",
        "  \n",
        "  #when training the projection net\n",
        "  #apply gradients to only the linear layer\n",
        "  def train_projection(self):\n",
        "    self._enet.eval()\n",
        "    self._pnet.train()\n",
        "  \n",
        "\n",
        "class SupContrastLoss(nn.Module):\n",
        "  \n",
        "  def __init__(self, device, T=1.0, EPS=1e-9):\n",
        "    super(SupContrastLoss, self).__init__()\n",
        "    self._T = T\n",
        "    self._EPS = EPS\n",
        "    self._softmax = nn.Softmax(dim=1)\n",
        "    self._device = device\n",
        "\n",
        "  def forward(self, z, y):\n",
        "    #z is a shape of (batch_size * 2, num of classes)\n",
        "    #y is a shape of (batch_size)\n",
        "    batch_size = z.size(0) // 2\n",
        "    shape_ = (2 * batch_size, 2 * batch_size)\n",
        "\n",
        "    #Iyy is an (2 * batch x 2* batch) maxtrix \n",
        "    #Iyy (i, j) = 0 if y[i] == y[j] or i == j\n",
        "    #else Iyy(i, j) = 1\n",
        "    Iyy = torch.eq(torch.cat([y.unsqueeze(dim=1), y.unsqueeze(dim=1)], dim=0),\n",
        "                   torch.cat([y.unsqueeze(dim=1), y.unsqueeze(dim=1)], dim=0).T).float() - torch.eye(2*batch_size).to(self._device)\n",
        "    \n",
        "    #softmax(z * z.T) is softmax of all i,j pairs\n",
        "    #apply mask of zero diagonals\n",
        "    #apply L1 normalization to obtain Pij\n",
        "    #self._EPS is used to avoid nan\n",
        "    Pij = F.normalize(self._softmax(torch.mm(z, z.T)) * \n",
        "                      (torch.ones(shape_).to(self._device) - (1 - self._EPS) * torch.eye(2*batch_size).to(self._device)), p=1, dim=1)\n",
        "    \n",
        "    #since Iyy has 0 diagonals, we need to use 2n+1 instead of 2n-1 as in the paper\n",
        "    loss = - torch.sum(torch.div(torch.sum(Iyy * torch.log(Pij + self._EPS), dim=1), 2 * torch.sum(Iyy, dim=1) + 1))\n",
        "    return loss\n",
        "\n",
        "class SupCrossEntropyLoss(nn.Module):\n",
        "\n",
        "  def __init__(self, device):\n",
        "    super(SupCrossEntropyLoss, self).__init__()\n",
        "\n",
        "    self._cross_entropy = nn.CrossEntropyLoss()\n",
        "    self._device = device\n",
        "  \n",
        "  def forward(self, y_, y):\n",
        "    #y_ is the size of [2 * batch_size, number of classes]\n",
        "    #y is the size of [batch_size]\n",
        "    return self._cross_entropy(y_, torch.cat([y.unsqueeze(dim=1), y.unsqueeze(dim=1)], dim=0).squeeze(dim=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2tq28Xc4HIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def backprop(loss, optimizer):\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "def Train(enet, pnet, trainloader, valloader, epochs, lr, T, start_epoch, device, state):\n",
        "  scnet = SupConNet(enet, pnet)\n",
        "  scnet.to(device)\n",
        "  optimizer = optim.Adam(scnet.parameters(), lr=lr)\n",
        "  min_val_loss = 1e20\n",
        "\n",
        "  if state == 'embedding':\n",
        "    loss_fn = SupContrastLoss(device, T=T).to(device)\n",
        "  elif state == 'projection':\n",
        "    loss_fn = SupCrossEntropyLoss(device).to(device)\n",
        "  else:\n",
        "    raise NameError('state arg should be embedding or projection')\n",
        "\n",
        "  for epoch in trange(epochs):\n",
        "\n",
        "    losses = []\n",
        "    \n",
        "    if state=='embedding':\n",
        "      scnet.train_embedding()\n",
        "    else:\n",
        "      scnet.train_projection()\n",
        "    for step, (x, y) in enumerate(trainloader):\n",
        "      x1, x2 = x[0], x[1]\n",
        "      x1, x2, y = x1.to(device), x2.to(device), y.to(device)\n",
        "\n",
        "      z = scnet(x1, x2)\n",
        "      loss = loss_fn(z, y)\n",
        "      backprop(loss, optimizer)\n",
        "\n",
        "      losses.append(loss.item())\n",
        "    avg_train_loss = sum(losses) / len(losses)\n",
        "\n",
        "    scnet.eval()\n",
        "    for step, (x, y) in enumerate(valloader):\n",
        "      x1, x2 = x[0], x[1]\n",
        "      x1, x2, y = x1.to(device), x2.to(device), y.to(device)\n",
        "\n",
        "      z = scnet(x1, x2)\n",
        "      loss = loss_fn(z, y)\n",
        "      losses.append(loss.item())\n",
        "    avg_val_loss = sum(losses) / len(losses)\n",
        "\n",
        "    if avg_val_loss < min_val_loss:\n",
        "      min_val_loss = avg_val_loss\n",
        "      if state=='embedding':\n",
        "        torch.save(enet.state_dict(), f'/content/gdrive/My Drive/state_dict/enet_checkpoint{epoch + start_epoch }.pt')\n",
        "      else:\n",
        "        torch.save(scnet.state_dict(), f'/content/gdrive/My Drive/state_dict/scnet_checkpoint{epoch + start_epoch}.pt')\n",
        "    print(f'\\n epoch {epoch + start_epoch} finished ====> train loss : {avg_train_loss}, val loss : {avg_val_loss}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QubODYa8NERC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enet = Encoder(40)\n",
        "enet.load_state_dict(torch.load('/content/gdrive/My Drive/state_dict/enet_checkpoint25.pt'))\n",
        "start_epoch = 25\n",
        "pnet1 = Projection(40, output_size, type_='perceptron')\n",
        "from torch import autograd\n",
        "#with autograd.detect_anomaly():\n",
        "Train(enet, pnet1, train_loader, val_loader, config['epochs_embed'], config['lr_embed'], config['T'], start_epoch, device, 'embedding')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I980IFdAQaQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enet.load_state_dict(torch.load('/content/gdrive/My Drive/state_dict/enet_checkpoint108.pt'))\n",
        "pnet2 = Projection(40, output_size, type_='linear')\n",
        "Train(enet, pnet2, train_loader, val_loader, config['epochs_proj'], config['lr_proj'], config['T'], 0, device, 'projection')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6zZqGr9SPnj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}